{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36192df7face4123a1079fe2456de9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_220281ef3d4f49169862c54fd2c7aab6",
              "IPY_MODEL_97b180321d8144b497fa041f04997330",
              "IPY_MODEL_e3b5c976060f4a018ac7882b2ff68b59"
            ],
            "layout": "IPY_MODEL_2a44cb79ce98478dab6baa5db864ecf0"
          }
        },
        "220281ef3d4f49169862c54fd2c7aab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca77e291cbcc4b91836209d7b47b31a6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7dc578c16541485ca68786a489589b19",
            "value": "config.json:‚Äá"
          }
        },
        "97b180321d8144b497fa041f04997330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf919004c0c94f7389badd20980d8ad8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60dafe7f885a4593a36bcc9bbcee56a6",
            "value": 1
          }
        },
        "e3b5c976060f4a018ac7882b2ff68b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_118fcc0452d3421ea5c52e571efb0ec9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a912d35ca1fe41dda66d98035feb16d0",
            "value": "‚Äá1.57k/?‚Äá[00:00&lt;00:00,‚Äá135kB/s]"
          }
        },
        "2a44cb79ce98478dab6baa5db864ecf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca77e291cbcc4b91836209d7b47b31a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc578c16541485ca68786a489589b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf919004c0c94f7389badd20980d8ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "60dafe7f885a4593a36bcc9bbcee56a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "118fcc0452d3421ea5c52e571efb0ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a912d35ca1fe41dda66d98035feb16d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b9bacb1d6e4f14b53f05ee58493d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7a9acfb6ca54bfc990d0e13e78aae31",
              "IPY_MODEL_354336c985a749c1a38eded40c07f924",
              "IPY_MODEL_7444260c38fc404eabfdc169f9648cfe"
            ],
            "layout": "IPY_MODEL_6f7a15d201c64a8a8c1c35a309ca11a4"
          }
        },
        "e7a9acfb6ca54bfc990d0e13e78aae31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c5d77de9554b9b9e9cb69a4d435932",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3cecef70a397493081fc1387a1b7f6e6",
            "value": "pytorch_model.bin:‚Äá100%"
          }
        },
        "354336c985a749c1a38eded40c07f924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872d8058905144c7a83f050892b08d8c",
            "max": 1269737156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cee8ce1a0794c81899e2b90d0329bee",
            "value": 1269737156
          }
        },
        "7444260c38fc404eabfdc169f9648cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f4feccecde4e378e88870fa13018ca",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_25ea4b4a1e904ed19c1f927098fce088",
            "value": "‚Äá1.27G/1.27G‚Äá[00:17&lt;00:00,‚Äá67.7MB/s]"
          }
        },
        "6f7a15d201c64a8a8c1c35a309ca11a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c5d77de9554b9b9e9cb69a4d435932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cecef70a397493081fc1387a1b7f6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "872d8058905144c7a83f050892b08d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cee8ce1a0794c81899e2b90d0329bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63f4feccecde4e378e88870fa13018ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ea4b4a1e904ed19c1f927098fce088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85f999437a774bec9dc5f68fcf14ecf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_797dbed5e2b34b25ad9ca1617dcc29e6",
              "IPY_MODEL_abf810eee7f847dc90b14e560f8d99b3",
              "IPY_MODEL_1baad693b5264478bc2d4cc46a6932cc"
            ],
            "layout": "IPY_MODEL_f883f27374534b01bbeeb4c8e923e5b9"
          }
        },
        "797dbed5e2b34b25ad9ca1617dcc29e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0bb13624464b3da2c2655a614ef856",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0757eecb536547e081acacd6d4928924",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "abf810eee7f847dc90b14e560f8d99b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1143e84fe6294fb18f6e64d4d73569a1",
            "max": 1269615400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29b998b4886848ca89106c9179101cca",
            "value": 1269615400
          }
        },
        "1baad693b5264478bc2d4cc46a6932cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54e8a5324a4b4ce98ea694f3c7fd6c61",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_19dc67471859430382d68f5b175ca171",
            "value": "‚Äá1.27G/1.27G‚Äá[00:14&lt;00:00,‚Äá190MB/s]"
          }
        },
        "f883f27374534b01bbeeb4c8e923e5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0bb13624464b3da2c2655a614ef856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0757eecb536547e081acacd6d4928924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1143e84fe6294fb18f6e64d4d73569a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b998b4886848ca89106c9179101cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54e8a5324a4b4ce98ea694f3c7fd6c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19dc67471859430382d68f5b175ca171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_XYwsMddF-X",
        "outputId": "8e91d96c-f647-4b65-b54a-c977a31a2071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers[torch] datasets[audio] accelerate evaluate jiwer librosa torchcodec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load G drive and change directory"
      ],
      "metadata": {
        "id": "zzUD4PXRdlT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hra5C1YWdnBZ",
        "outputId": "fb1f9b80-4980-4c16-bc59-7d9922fd4ee0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/sinhala_pronunciation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOaOxds2dp8R",
        "outputId": "2c6f6dc8-7a24-4dc7-8494-79228564109d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/sinhala_pronunciation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Loader"
      ],
      "metadata": {
        "id": "ofejHPGTdqtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_loader.py\n",
        "import os, json, torch, torchaudio\n",
        "\n",
        "root = \"/content/drive/MyDrive/sinhala_pronunciation/dataset\"\n",
        "\n",
        "import os, json, torch, torchaudio\n",
        "\n",
        "class SinhalaDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.samples = []\n",
        "        with open(f\"{root}/phonemes.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "            self.data_map = json.load(f)\n",
        "\n",
        "        for folder_name, info in self.data_map.items():\n",
        "            folder_path = os.path.join(root, folder_name)\n",
        "\n",
        "            if os.path.exists(folder_path):\n",
        "                for f in os.listdir(folder_path):\n",
        "                    if f.endswith(\".wav\"):\n",
        "                        # Store the path AND the specific phoneme list\n",
        "                        self.samples.append((os.path.join(folder_path, f), info[\"phonemes\"]))\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Missing folder: {folder_path}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        wav_path, phonemes = self.samples[idx]\n",
        "        wav, sr = torchaudio.load(wav_path)\n",
        "        if sr != 16000:\n",
        "            wav = torchaudio.functional.resample(wav, sr, 16000)\n",
        "\n",
        "        return wav.squeeze(), phonemes\n"
      ],
      "metadata": {
        "id": "AX-vXhzedu0e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test data loading"
      ],
      "metadata": {
        "id": "jI4nrA8md0DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SinhalaDataset(root)\n",
        "print(len(dataset))\n",
        "\n",
        "wav, phones = dataset[0]\n",
        "print(wav.shape)\n",
        "print(phones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxqQSSYKd2Nm",
        "outputId": "289dc2fc-7922-41f2-d0e9-b82fdad6065d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1618\n",
            "torch.Size([11201])\n",
            "['b', 'a', 'l', 'l', 'a:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating vocabulary with mappings for etc"
      ],
      "metadata": {
        "id": "QxdKPsl6d4C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# existing vocab\n",
        "existing_vocab = {\n",
        "    \"a\": 0, \"a:\": 1, \"b\": 2, \"l\": 3, \"i\": 4, \"d\": 5, \"th\": 6,\n",
        "    \"p\": 7, \"o\": 8, \"k\": 9, \"s\": 10, \"m\": 11, \"n\": 12, \"y\": 13,\n",
        "    \"u\": 14, \"r\": 15, \"w\": 16, \"h\": 17, \"g\": 18, \"i:\": 19, \"sh\": 20\n",
        "}\n",
        "\n",
        "training_vocab = existing_vocab.copy()\n",
        "training_vocab[\"[PAD]\"] = 21\n",
        "training_vocab[\"[UNK]\"] = 22\n",
        "\n",
        "with open(\"vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(training_vocab, f)\n",
        "\n",
        "print(f\"‚úÖ Created training vocab with {len(training_vocab)} tokens.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OtJwLMUd8FD",
        "outputId": "4929c3ca-f1d4-439e-b15d-85d4d95d5a57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created training vocab with 23 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training execution"
      ],
      "metadata": {
        "id": "PzQuZIodeDpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "# --- 1. SET DEVICE ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 2. LOAD VOCAB & PROCESSOR ---\n",
        "with open(\"vocab.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    training_vocab = json.load(f)\n",
        "\n",
        "tokenizer = Wav2Vec2CTCTokenizer(\n",
        "    \"./vocab.json\",\n",
        "    unk_token=\"[UNK]\",\n",
        "    pad_token=\"[PAD]\",\n",
        "    word_delimiter_token=None\n",
        ")\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(\n",
        "    feature_size=1, sampling_rate=16000, padding_value=0.0,\n",
        "    do_normalize=True, return_attention_mask=True\n",
        ")\n",
        "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "\n",
        "from transformers import Wav2Vec2Config\n",
        "\n",
        "# --- 3. LOAD MODEL ---\n",
        "config = Wav2Vec2Config.from_pretrained(\"facebook/wav2vec2-xls-r-300m\")\n",
        "\n",
        "# 2. Update config with specific parameters\n",
        "config.ctc_loss_reduction = \"mean\"\n",
        "config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "config.vocab_size = len(processor.tokenizer)\n",
        "# config.ctc_blank_id = training_vocab.get(\"[BLANK]\", 0)\n",
        "\n",
        "# 3. Load the model using this config\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\n",
        "    \"facebook/wav2vec2-xls-r-300m\",\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True # Required because, changed vocab_size\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "model.freeze_feature_encoder()\n",
        "\n",
        "# --- 4. DATA COLLATOR ---\n",
        "def collate_fn(batch):\n",
        "    # Separate the waveforms and the phoneme lists\n",
        "    audio_list = [item[0].numpy() for item in batch]\n",
        "    phoneme_lists = [item[1] for item in batch]\n",
        "\n",
        "    # 1. Process Audio (Input)\n",
        "    inputs = processor(\n",
        "        audio_list,\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    # 2. Process Labels (Target) using the tokenizer directly\n",
        "    # This avoids the 'multiple values for padding' error\n",
        "    labels_batch = processor.tokenizer(\n",
        "        phoneme_lists,\n",
        "        is_split_into_words=True,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Replace padding index with -100 so CTC loss ignores it\n",
        "    labels = labels_batch.input_ids.masked_fill(\n",
        "        labels_batch.input_ids == processor.tokenizer.pad_token_id, -100\n",
        "    )\n",
        "\n",
        "    return inputs.input_values.to(device), labels.to(device)\n",
        "\n",
        "# --- 5. STABILIZED TRAINING LOOP ---\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# 1. Update Config to handle infinite loss\n",
        "model.config.ctc_zero_infinity = True\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5) # used 1e-4\n",
        "\n",
        "model.train()\n",
        "print(\"üöÄ Starting stabilized training...\")\n",
        "\n",
        "for epoch in range(30):\n",
        "\n",
        "    if epoch == 5:\n",
        "      for param in model.wav2vec2.feature_extractor.parameters():\n",
        "          param.requires_grad = True\n",
        "      print(\"üîì Feature extractor unfrozen\")\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (inputs, labels) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_values=inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # 2. Check for NaN before backprop\n",
        "        if torch.isnan(loss):\n",
        "            print(f\"‚ö†Ô∏è Skip NaN batch {batch_idx}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # 3. Gradient Clipping (Crucial for stability)\n",
        "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Batch {batch_idx} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = epoch_loss / len(loader)\n",
        "    print(f\"‚úÖ Epoch {epoch} | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# --- 6. SAVE ---\n",
        "model.save_pretrained(\"sinhala-pronunciation-model\")\n",
        "processor.save_pretrained(\"sinhala-pronunciation-model\")\n",
        "print(\"üíæ Done! Model saved to 'sinhala-pronunciation-model' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36192df7face4123a1079fe2456de9ba",
            "220281ef3d4f49169862c54fd2c7aab6",
            "97b180321d8144b497fa041f04997330",
            "e3b5c976060f4a018ac7882b2ff68b59",
            "2a44cb79ce98478dab6baa5db864ecf0",
            "ca77e291cbcc4b91836209d7b47b31a6",
            "7dc578c16541485ca68786a489589b19",
            "cf919004c0c94f7389badd20980d8ad8",
            "60dafe7f885a4593a36bcc9bbcee56a6",
            "118fcc0452d3421ea5c52e571efb0ec9",
            "a912d35ca1fe41dda66d98035feb16d0",
            "82b9bacb1d6e4f14b53f05ee58493d80",
            "e7a9acfb6ca54bfc990d0e13e78aae31",
            "354336c985a749c1a38eded40c07f924",
            "7444260c38fc404eabfdc169f9648cfe",
            "6f7a15d201c64a8a8c1c35a309ca11a4",
            "69c5d77de9554b9b9e9cb69a4d435932",
            "3cecef70a397493081fc1387a1b7f6e6",
            "872d8058905144c7a83f050892b08d8c",
            "3cee8ce1a0794c81899e2b90d0329bee",
            "63f4feccecde4e378e88870fa13018ca",
            "25ea4b4a1e904ed19c1f927098fce088",
            "85f999437a774bec9dc5f68fcf14ecf5",
            "797dbed5e2b34b25ad9ca1617dcc29e6",
            "abf810eee7f847dc90b14e560f8d99b3",
            "1baad693b5264478bc2d4cc46a6932cc",
            "f883f27374534b01bbeeb4c8e923e5b9",
            "0f0bb13624464b3da2c2655a614ef856",
            "0757eecb536547e081acacd6d4928924",
            "1143e84fe6294fb18f6e64d4d73569a1",
            "29b998b4886848ca89106c9179101cca",
            "54e8a5324a4b4ce98ea694f3c7fd6c61",
            "19dc67471859430382d68f5b175ca171"
          ]
        },
        "id": "6gjcjO3keEV3",
        "outputId": "6e077f60-51c8-4abf-9273-692e972ef607"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36192df7face4123a1079fe2456de9ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82b9bacb1d6e4f14b53f05ee58493d80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85f999437a774bec9dc5f68fcf14ecf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting stabilized training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cudnn/__init__.py:145: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  torch._C._get_cudnn_allow_tf32(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 | Loss: 7.2756\n",
            "Batch 10 | Loss: 6.4037\n",
            "Batch 20 | Loss: 4.4158\n",
            "Batch 30 | Loss: 3.7425\n",
            "Batch 40 | Loss: 4.8708\n",
            "Batch 50 | Loss: 3.9564\n",
            "Batch 60 | Loss: 4.0755\n",
            "Batch 70 | Loss: 2.9860\n",
            "Batch 80 | Loss: 3.4028\n",
            "Batch 90 | Loss: 2.6214\n",
            "Batch 100 | Loss: 5.7311\n",
            "Batch 110 | Loss: 2.6829\n",
            "Batch 120 | Loss: 2.4652\n",
            "Batch 130 | Loss: 2.3258\n",
            "Batch 140 | Loss: 2.2496\n",
            "Batch 150 | Loss: 2.8086\n",
            "Batch 160 | Loss: 3.1029\n",
            "Batch 170 | Loss: 2.0758\n",
            "Batch 180 | Loss: 2.4174\n",
            "Batch 190 | Loss: 2.8950\n",
            "Batch 200 | Loss: 2.3165\n",
            "Batch 210 | Loss: 1.9810\n",
            "Batch 220 | Loss: 2.4647\n",
            "Batch 230 | Loss: 2.3010\n",
            "Batch 240 | Loss: 2.4806\n",
            "Batch 250 | Loss: 1.8934\n",
            "Batch 260 | Loss: 1.8882\n",
            "Batch 270 | Loss: 2.1695\n",
            "Batch 280 | Loss: 2.0475\n",
            "Batch 290 | Loss: 2.0253\n",
            "Batch 300 | Loss: 2.0163\n",
            "Batch 310 | Loss: 2.3516\n",
            "Batch 320 | Loss: 1.9330\n",
            "Batch 330 | Loss: 1.8207\n",
            "Batch 340 | Loss: 2.1306\n",
            "Batch 350 | Loss: 2.0591\n",
            "Batch 360 | Loss: 1.9089\n",
            "Batch 370 | Loss: 2.2079\n",
            "Batch 380 | Loss: 1.7488\n",
            "Batch 390 | Loss: 1.8864\n",
            "Batch 400 | Loss: 2.4366\n",
            "‚úÖ Epoch 0 | Avg Loss: 2.7245\n",
            "Batch 0 | Loss: 1.8102\n",
            "Batch 10 | Loss: 1.7115\n",
            "Batch 20 | Loss: 1.7045\n",
            "Batch 30 | Loss: 2.2094\n",
            "Batch 40 | Loss: 1.8903\n",
            "Batch 50 | Loss: 1.7075\n",
            "Batch 60 | Loss: 1.8653\n",
            "Batch 70 | Loss: 1.7889\n",
            "Batch 80 | Loss: 1.7932\n",
            "Batch 90 | Loss: 2.1648\n",
            "Batch 100 | Loss: 1.7772\n",
            "Batch 110 | Loss: 2.1412\n",
            "Batch 120 | Loss: 1.8891\n",
            "Batch 130 | Loss: 1.9276\n",
            "Batch 140 | Loss: 1.6999\n",
            "Batch 150 | Loss: 1.6811\n",
            "Batch 160 | Loss: 2.0433\n",
            "Batch 170 | Loss: 1.7722\n",
            "Batch 180 | Loss: 1.6486\n",
            "Batch 190 | Loss: 1.8025\n",
            "Batch 200 | Loss: 1.9381\n",
            "Batch 210 | Loss: 1.8305\n",
            "Batch 220 | Loss: 2.2249\n",
            "Batch 230 | Loss: 1.8273\n",
            "Batch 240 | Loss: 1.8660\n",
            "Batch 250 | Loss: 1.7949\n",
            "Batch 260 | Loss: 1.7863\n",
            "Batch 270 | Loss: 2.3986\n",
            "Batch 280 | Loss: 1.6822\n",
            "Batch 290 | Loss: 1.6094\n",
            "Batch 300 | Loss: 2.1872\n",
            "Batch 310 | Loss: 1.6700\n",
            "Batch 320 | Loss: 1.6443\n",
            "Batch 330 | Loss: 2.0479\n",
            "Batch 340 | Loss: 1.6547\n",
            "Batch 350 | Loss: 1.6755\n",
            "Batch 360 | Loss: 1.6583\n",
            "Batch 370 | Loss: 1.7418\n",
            "Batch 380 | Loss: 1.5909\n",
            "Batch 390 | Loss: 1.9305\n",
            "Batch 400 | Loss: 1.8746\n",
            "‚úÖ Epoch 1 | Avg Loss: 1.8527\n",
            "Batch 0 | Loss: 1.7570\n",
            "Batch 10 | Loss: 1.6702\n",
            "Batch 20 | Loss: 1.5578\n",
            "Batch 30 | Loss: 1.6299\n",
            "Batch 40 | Loss: 1.8130\n",
            "Batch 50 | Loss: 1.7444\n",
            "Batch 60 | Loss: 1.6857\n",
            "Batch 70 | Loss: 1.6155\n",
            "Batch 80 | Loss: 1.8702\n",
            "Batch 90 | Loss: 1.6688\n",
            "Batch 100 | Loss: 1.6824\n",
            "Batch 110 | Loss: 1.6812\n",
            "Batch 120 | Loss: 1.6741\n",
            "Batch 130 | Loss: 1.7831\n",
            "Batch 140 | Loss: 1.7444\n",
            "Batch 150 | Loss: 1.5782\n",
            "Batch 160 | Loss: 1.8876\n",
            "Batch 170 | Loss: 1.6464\n",
            "Batch 180 | Loss: 1.8983\n",
            "Batch 190 | Loss: 1.8143\n",
            "Batch 200 | Loss: 1.7851\n",
            "Batch 210 | Loss: 1.8264\n",
            "Batch 220 | Loss: 1.2622\n",
            "Batch 230 | Loss: 1.5489\n",
            "Batch 240 | Loss: 1.6211\n",
            "Batch 250 | Loss: 1.5729\n",
            "Batch 260 | Loss: 1.8064\n",
            "Batch 270 | Loss: 1.6298\n",
            "Batch 280 | Loss: 1.9031\n",
            "Batch 290 | Loss: 1.6761\n",
            "Batch 300 | Loss: 1.6323\n",
            "Batch 310 | Loss: 1.6198\n",
            "Batch 320 | Loss: 1.7374\n",
            "Batch 330 | Loss: 1.8057\n",
            "Batch 340 | Loss: 1.8362\n",
            "Batch 350 | Loss: 1.7467\n",
            "Batch 360 | Loss: 1.6460\n",
            "Batch 370 | Loss: 1.7608\n",
            "Batch 380 | Loss: 1.8870\n",
            "Batch 390 | Loss: 1.7845\n",
            "Batch 400 | Loss: 1.6440\n",
            "‚úÖ Epoch 2 | Avg Loss: 1.7131\n",
            "Batch 0 | Loss: 1.6372\n",
            "Batch 10 | Loss: 2.0274\n",
            "Batch 20 | Loss: 1.6603\n",
            "Batch 30 | Loss: 1.5528\n",
            "Batch 40 | Loss: 1.5745\n",
            "Batch 50 | Loss: 1.6369\n",
            "Batch 60 | Loss: 1.5596\n",
            "Batch 70 | Loss: 1.7161\n",
            "Batch 80 | Loss: 1.7425\n",
            "Batch 90 | Loss: 1.6496\n",
            "Batch 100 | Loss: 1.5437\n",
            "Batch 110 | Loss: 1.5913\n",
            "Batch 120 | Loss: 2.0088\n",
            "Batch 130 | Loss: 1.6749\n",
            "Batch 140 | Loss: 1.7564\n",
            "Batch 150 | Loss: 1.6731\n",
            "Batch 160 | Loss: 1.7850\n",
            "Batch 170 | Loss: 1.5497\n",
            "Batch 180 | Loss: 1.6056\n",
            "Batch 190 | Loss: 2.3091\n",
            "Batch 200 | Loss: 1.6507\n",
            "Batch 210 | Loss: 1.8193\n",
            "Batch 220 | Loss: 1.7062\n",
            "Batch 230 | Loss: 1.6980\n",
            "Batch 240 | Loss: 1.4885\n",
            "Batch 250 | Loss: 1.6338\n",
            "Batch 260 | Loss: 1.6108\n",
            "Batch 270 | Loss: 1.8722\n",
            "Batch 280 | Loss: 1.6726\n",
            "Batch 290 | Loss: 1.6379\n",
            "Batch 300 | Loss: 1.7677\n",
            "Batch 310 | Loss: 1.5877\n",
            "Batch 320 | Loss: 1.5417\n",
            "Batch 330 | Loss: 1.6806\n",
            "Batch 340 | Loss: 1.6237\n",
            "Batch 350 | Loss: 1.5877\n",
            "Batch 360 | Loss: 1.5537\n",
            "Batch 370 | Loss: 1.8606\n",
            "Batch 380 | Loss: 1.8627\n",
            "Batch 390 | Loss: 1.6842\n",
            "Batch 400 | Loss: 1.6248\n",
            "‚úÖ Epoch 3 | Avg Loss: 1.6690\n",
            "Batch 0 | Loss: 1.6519\n",
            "Batch 10 | Loss: 1.7381\n",
            "Batch 20 | Loss: 1.6525\n",
            "Batch 30 | Loss: 1.6932\n",
            "Batch 40 | Loss: 1.5673\n",
            "Batch 50 | Loss: 1.8638\n",
            "Batch 60 | Loss: 1.7036\n",
            "Batch 70 | Loss: 1.6784\n",
            "Batch 80 | Loss: 1.7911\n",
            "Batch 90 | Loss: 1.6394\n",
            "Batch 100 | Loss: 1.6708\n",
            "Batch 110 | Loss: 1.7281\n",
            "Batch 120 | Loss: 1.5426\n",
            "Batch 130 | Loss: 1.6536\n",
            "Batch 140 | Loss: 1.8444\n",
            "Batch 150 | Loss: 1.6686\n",
            "Batch 160 | Loss: 2.0815\n",
            "Batch 170 | Loss: 1.8722\n",
            "Batch 180 | Loss: 1.6577\n",
            "Batch 190 | Loss: 1.6194\n",
            "Batch 200 | Loss: 1.7406\n",
            "Batch 210 | Loss: 1.5908\n",
            "Batch 220 | Loss: 1.5946\n",
            "Batch 230 | Loss: 1.6114\n",
            "Batch 240 | Loss: 1.6506\n",
            "Batch 250 | Loss: 1.6748\n",
            "Batch 260 | Loss: 1.5434\n",
            "Batch 270 | Loss: 1.4975\n",
            "Batch 280 | Loss: 1.6709\n",
            "Batch 290 | Loss: 1.9017\n",
            "Batch 300 | Loss: 1.6067\n",
            "Batch 310 | Loss: 1.5025\n",
            "Batch 320 | Loss: 1.6404\n",
            "Batch 330 | Loss: 1.6712\n",
            "Batch 340 | Loss: 1.5374\n",
            "Batch 350 | Loss: 1.6374\n",
            "Batch 360 | Loss: 1.7981\n",
            "Batch 370 | Loss: 1.5734\n",
            "Batch 380 | Loss: 1.5307\n",
            "Batch 390 | Loss: 1.4419\n",
            "Batch 400 | Loss: 1.5904\n",
            "‚úÖ Epoch 4 | Avg Loss: 1.6265\n",
            "üîì Feature extractor unfrozen\n",
            "Batch 0 | Loss: 1.4321\n",
            "Batch 10 | Loss: 1.6053\n",
            "Batch 20 | Loss: 1.5646\n",
            "Batch 30 | Loss: 1.5719\n",
            "Batch 40 | Loss: 1.4761\n",
            "Batch 50 | Loss: 1.8762\n",
            "Batch 60 | Loss: 1.6419\n",
            "Batch 70 | Loss: 1.5156\n",
            "Batch 80 | Loss: 1.4185\n",
            "Batch 90 | Loss: 1.8640\n",
            "Batch 100 | Loss: 1.6428\n",
            "Batch 110 | Loss: 1.6281\n",
            "Batch 120 | Loss: 1.6792\n",
            "Batch 130 | Loss: 1.5980\n",
            "Batch 140 | Loss: 1.5022\n",
            "Batch 150 | Loss: 1.4437\n",
            "Batch 160 | Loss: 1.4053\n",
            "Batch 170 | Loss: 1.5856\n",
            "Batch 180 | Loss: 1.4287\n",
            "Batch 190 | Loss: 1.5026\n",
            "Batch 200 | Loss: 1.4515\n",
            "Batch 210 | Loss: 1.5684\n",
            "Batch 220 | Loss: 1.5461\n",
            "Batch 230 | Loss: 1.4485\n",
            "Batch 240 | Loss: 1.4266\n",
            "Batch 250 | Loss: 1.4096\n",
            "Batch 260 | Loss: 1.4594\n",
            "Batch 270 | Loss: 1.3786\n",
            "Batch 280 | Loss: 1.4654\n",
            "Batch 290 | Loss: 1.5424\n",
            "Batch 300 | Loss: 1.3814\n",
            "Batch 310 | Loss: 1.5038\n",
            "Batch 320 | Loss: 1.3476\n",
            "Batch 330 | Loss: 1.4273\n",
            "Batch 340 | Loss: 1.4762\n",
            "Batch 350 | Loss: 1.4743\n",
            "Batch 360 | Loss: 1.6169\n",
            "Batch 370 | Loss: 1.3603\n",
            "Batch 380 | Loss: 1.3233\n",
            "Batch 390 | Loss: 1.4442\n",
            "Batch 400 | Loss: 1.3438\n",
            "‚úÖ Epoch 5 | Avg Loss: 1.4811\n",
            "Batch 0 | Loss: 1.4545\n",
            "Batch 10 | Loss: 1.4266\n",
            "Batch 20 | Loss: 1.2951\n",
            "Batch 30 | Loss: 1.3425\n",
            "Batch 40 | Loss: 1.2981\n",
            "Batch 50 | Loss: 1.3759\n",
            "Batch 60 | Loss: 1.4149\n",
            "Batch 70 | Loss: 1.7121\n",
            "Batch 80 | Loss: 1.4311\n",
            "Batch 90 | Loss: 1.6030\n",
            "Batch 100 | Loss: 1.4097\n",
            "Batch 110 | Loss: 1.5182\n",
            "Batch 120 | Loss: 1.6249\n",
            "Batch 130 | Loss: 1.2554\n",
            "Batch 140 | Loss: 1.3572\n",
            "Batch 150 | Loss: 1.3211\n",
            "Batch 160 | Loss: 1.4547\n",
            "Batch 170 | Loss: 1.2607\n",
            "Batch 180 | Loss: 1.3821\n",
            "Batch 190 | Loss: 1.2224\n",
            "Batch 200 | Loss: 1.2072\n",
            "Batch 210 | Loss: 1.1424\n",
            "Batch 220 | Loss: 1.2616\n",
            "Batch 230 | Loss: 1.5626\n",
            "Batch 240 | Loss: 1.4402\n",
            "Batch 250 | Loss: 1.5893\n",
            "Batch 260 | Loss: 1.3541\n",
            "Batch 270 | Loss: 1.1240\n",
            "Batch 280 | Loss: 1.1341\n",
            "Batch 290 | Loss: 1.0261\n",
            "Batch 300 | Loss: 1.1334\n",
            "Batch 310 | Loss: 1.2220\n",
            "Batch 320 | Loss: 1.4401\n",
            "Batch 330 | Loss: 1.3579\n",
            "Batch 340 | Loss: 1.3704\n",
            "Batch 350 | Loss: 1.1685\n",
            "Batch 360 | Loss: 1.4013\n",
            "Batch 370 | Loss: 1.3391\n",
            "Batch 380 | Loss: 0.9015\n",
            "Batch 390 | Loss: 1.2203\n",
            "Batch 400 | Loss: 1.3719\n",
            "‚úÖ Epoch 6 | Avg Loss: 1.3346\n",
            "Batch 0 | Loss: 1.1370\n",
            "Batch 10 | Loss: 1.5909\n",
            "Batch 20 | Loss: 1.5481\n",
            "Batch 30 | Loss: 1.2968\n",
            "Batch 40 | Loss: 1.4631\n",
            "Batch 50 | Loss: 1.1965\n",
            "Batch 60 | Loss: 1.1091\n",
            "Batch 70 | Loss: 1.2391\n",
            "Batch 80 | Loss: 1.1087\n",
            "Batch 90 | Loss: 1.4325\n",
            "Batch 100 | Loss: 1.3054\n",
            "Batch 110 | Loss: 1.2840\n",
            "Batch 120 | Loss: 1.2478\n",
            "Batch 130 | Loss: 1.3845\n",
            "Batch 140 | Loss: 1.3146\n",
            "Batch 150 | Loss: 1.2170\n",
            "Batch 160 | Loss: 1.4291\n",
            "Batch 170 | Loss: 1.4969\n",
            "Batch 180 | Loss: 1.0805\n",
            "Batch 190 | Loss: 0.9842\n",
            "Batch 200 | Loss: 1.0040\n",
            "Batch 210 | Loss: 1.4753\n",
            "Batch 220 | Loss: 1.2172\n",
            "Batch 230 | Loss: 1.3543\n",
            "Batch 240 | Loss: 1.2017\n",
            "Batch 250 | Loss: 1.2507\n",
            "Batch 260 | Loss: 1.4475\n",
            "Batch 270 | Loss: 1.0587\n",
            "Batch 280 | Loss: 1.1513\n",
            "Batch 290 | Loss: 1.2012\n",
            "Batch 300 | Loss: 0.9576\n",
            "Batch 310 | Loss: 1.2647\n",
            "Batch 320 | Loss: 1.3365\n",
            "Batch 330 | Loss: 1.1382\n",
            "Batch 340 | Loss: 1.0947\n",
            "Batch 350 | Loss: 1.8717\n",
            "Batch 360 | Loss: 1.0717\n",
            "Batch 370 | Loss: 1.4281\n",
            "Batch 380 | Loss: 1.2401\n",
            "Batch 390 | Loss: 1.3519\n",
            "Batch 400 | Loss: 1.5185\n",
            "‚úÖ Epoch 7 | Avg Loss: 1.2414\n",
            "Batch 0 | Loss: 0.9334\n",
            "Batch 10 | Loss: 1.0139\n",
            "Batch 20 | Loss: 1.0008\n",
            "Batch 30 | Loss: 1.1799\n",
            "Batch 40 | Loss: 0.8838\n",
            "Batch 50 | Loss: 1.3097\n",
            "Batch 60 | Loss: 1.2065\n",
            "Batch 70 | Loss: 1.1517\n",
            "Batch 80 | Loss: 1.2131\n",
            "Batch 90 | Loss: 1.1389\n",
            "Batch 100 | Loss: 1.2575\n",
            "Batch 110 | Loss: 1.2375\n",
            "Batch 120 | Loss: 1.0739\n",
            "Batch 130 | Loss: 1.1544\n",
            "Batch 140 | Loss: 1.2948\n",
            "Batch 150 | Loss: 0.9734\n",
            "Batch 160 | Loss: 0.7723\n",
            "Batch 170 | Loss: 1.1096\n",
            "Batch 180 | Loss: 1.0302\n",
            "Batch 190 | Loss: 1.2638\n",
            "Batch 200 | Loss: 1.2153\n",
            "Batch 210 | Loss: 1.3299\n",
            "Batch 220 | Loss: 1.3495\n",
            "Batch 230 | Loss: 1.0473\n",
            "Batch 240 | Loss: 1.2208\n",
            "Batch 250 | Loss: 1.1180\n",
            "Batch 260 | Loss: 1.3441\n",
            "Batch 270 | Loss: 1.2470\n",
            "Batch 280 | Loss: 0.9697\n",
            "Batch 290 | Loss: 1.2398\n",
            "Batch 300 | Loss: 1.0480\n",
            "Batch 310 | Loss: 0.9622\n",
            "Batch 320 | Loss: 0.9616\n",
            "Batch 330 | Loss: 0.9389\n",
            "Batch 340 | Loss: 0.9415\n",
            "Batch 350 | Loss: 0.9092\n",
            "Batch 360 | Loss: 1.2704\n",
            "Batch 370 | Loss: 1.1566\n",
            "Batch 380 | Loss: 1.2600\n",
            "Batch 390 | Loss: 0.9659\n",
            "Batch 400 | Loss: 1.4718\n",
            "‚úÖ Epoch 8 | Avg Loss: 1.1550\n",
            "Batch 0 | Loss: 1.4687\n",
            "Batch 10 | Loss: 1.5094\n",
            "Batch 20 | Loss: 1.2531\n",
            "Batch 30 | Loss: 0.9164\n",
            "Batch 40 | Loss: 0.8748\n",
            "Batch 50 | Loss: 1.5026\n",
            "Batch 60 | Loss: 1.3364\n",
            "Batch 70 | Loss: 1.0333\n",
            "Batch 80 | Loss: 1.1268\n",
            "Batch 90 | Loss: 0.8781\n",
            "Batch 100 | Loss: 0.9292\n",
            "Batch 110 | Loss: 0.9942\n",
            "Batch 120 | Loss: 1.1793\n",
            "Batch 130 | Loss: 0.9913\n",
            "Batch 140 | Loss: 0.9832\n",
            "Batch 150 | Loss: 1.2995\n",
            "Batch 160 | Loss: 1.0020\n",
            "Batch 170 | Loss: 1.2619\n",
            "Batch 180 | Loss: 1.0174\n",
            "Batch 190 | Loss: 1.1252\n",
            "Batch 200 | Loss: 0.9360\n",
            "Batch 210 | Loss: 1.1558\n",
            "Batch 220 | Loss: 0.8713\n",
            "Batch 230 | Loss: 1.2538\n",
            "Batch 240 | Loss: 1.0486\n",
            "Batch 250 | Loss: 1.5910\n",
            "Batch 260 | Loss: 1.3085\n",
            "Batch 270 | Loss: 1.0236\n",
            "Batch 280 | Loss: 1.1890\n",
            "Batch 290 | Loss: 1.0430\n",
            "Batch 300 | Loss: 0.8700\n",
            "Batch 310 | Loss: 1.0944\n",
            "Batch 320 | Loss: 1.4053\n",
            "Batch 330 | Loss: 0.8832\n",
            "Batch 340 | Loss: 0.8846\n",
            "Batch 350 | Loss: 1.1100\n",
            "Batch 360 | Loss: 1.2156\n",
            "Batch 370 | Loss: 1.2259\n",
            "Batch 380 | Loss: 1.3210\n",
            "Batch 390 | Loss: 1.3831\n",
            "Batch 400 | Loss: 1.0270\n",
            "‚úÖ Epoch 9 | Avg Loss: 1.1343\n",
            "Batch 0 | Loss: 0.9916\n",
            "Batch 10 | Loss: 1.0433\n",
            "Batch 20 | Loss: 1.0951\n",
            "Batch 30 | Loss: 0.9506\n",
            "Batch 40 | Loss: 1.0532\n",
            "Batch 50 | Loss: 0.9579\n",
            "Batch 60 | Loss: 1.0598\n",
            "Batch 70 | Loss: 1.3233\n",
            "Batch 80 | Loss: 1.1059\n",
            "Batch 90 | Loss: 0.9971\n",
            "Batch 100 | Loss: 1.0386\n",
            "Batch 110 | Loss: 1.1816\n",
            "Batch 120 | Loss: 1.1265\n",
            "Batch 130 | Loss: 1.0283\n",
            "Batch 140 | Loss: 1.0850\n",
            "Batch 150 | Loss: 1.0608\n",
            "Batch 160 | Loss: 0.9588\n",
            "Batch 170 | Loss: 1.0849\n",
            "Batch 180 | Loss: 1.0675\n",
            "Batch 190 | Loss: 1.0509\n",
            "Batch 200 | Loss: 0.8468\n",
            "Batch 210 | Loss: 0.9571\n",
            "Batch 220 | Loss: 1.5853\n",
            "Batch 230 | Loss: 0.8976\n",
            "Batch 240 | Loss: 1.0325\n",
            "Batch 250 | Loss: 0.9336\n",
            "Batch 260 | Loss: 1.1189\n",
            "Batch 270 | Loss: 1.1094\n",
            "Batch 280 | Loss: 1.2694\n",
            "Batch 290 | Loss: 1.1664\n",
            "Batch 300 | Loss: 1.2532\n",
            "Batch 310 | Loss: 0.8955\n",
            "Batch 320 | Loss: 1.2954\n",
            "Batch 330 | Loss: 1.1876\n",
            "Batch 340 | Loss: 1.0001\n",
            "Batch 350 | Loss: 1.0422\n",
            "Batch 360 | Loss: 1.0079\n",
            "Batch 370 | Loss: 1.0448\n",
            "Batch 380 | Loss: 1.2084\n",
            "Batch 390 | Loss: 0.9908\n",
            "Batch 400 | Loss: 0.8977\n",
            "‚úÖ Epoch 10 | Avg Loss: 1.1066\n",
            "Batch 0 | Loss: 1.2118\n",
            "Batch 10 | Loss: 0.8238\n",
            "Batch 20 | Loss: 1.0244\n",
            "Batch 30 | Loss: 1.3539\n",
            "Batch 40 | Loss: 1.1106\n",
            "Batch 50 | Loss: 1.2358\n",
            "Batch 60 | Loss: 1.0880\n",
            "Batch 70 | Loss: 0.9683\n",
            "Batch 80 | Loss: 1.0505\n",
            "Batch 90 | Loss: 1.4091\n",
            "Batch 100 | Loss: 0.8764\n",
            "Batch 110 | Loss: 1.0177\n",
            "Batch 120 | Loss: 1.0840\n",
            "Batch 130 | Loss: 1.2069\n",
            "Batch 140 | Loss: 0.8567\n",
            "Batch 150 | Loss: 1.0541\n",
            "Batch 160 | Loss: 1.5122\n",
            "Batch 170 | Loss: 1.0394\n",
            "Batch 180 | Loss: 0.7026\n",
            "Batch 190 | Loss: 1.2452\n",
            "Batch 200 | Loss: 0.9077\n",
            "Batch 210 | Loss: 0.9374\n",
            "Batch 220 | Loss: 1.0887\n",
            "Batch 230 | Loss: 1.0449\n",
            "Batch 240 | Loss: 0.9624\n",
            "Batch 250 | Loss: 0.9398\n",
            "Batch 260 | Loss: 0.9065\n",
            "Batch 270 | Loss: 0.9215\n",
            "Batch 280 | Loss: 0.9918\n",
            "Batch 290 | Loss: 1.1671\n",
            "Batch 300 | Loss: 1.0801\n",
            "Batch 310 | Loss: 0.8931\n",
            "Batch 320 | Loss: 0.9452\n",
            "Batch 330 | Loss: 0.7503\n",
            "Batch 340 | Loss: 0.9732\n",
            "Batch 350 | Loss: 0.9462\n",
            "Batch 360 | Loss: 0.9517\n",
            "Batch 370 | Loss: 1.0034\n",
            "Batch 380 | Loss: 1.0847\n",
            "Batch 390 | Loss: 1.2033\n",
            "Batch 400 | Loss: 1.1452\n",
            "‚úÖ Epoch 11 | Avg Loss: 1.0497\n",
            "Batch 0 | Loss: 1.0836\n",
            "Batch 10 | Loss: 0.9095\n",
            "Batch 20 | Loss: 0.9664\n",
            "Batch 30 | Loss: 0.9282\n",
            "Batch 40 | Loss: 1.0244\n",
            "Batch 50 | Loss: 0.9428\n",
            "Batch 60 | Loss: 0.9371\n",
            "Batch 70 | Loss: 1.1808\n",
            "Batch 80 | Loss: 1.0785\n",
            "Batch 90 | Loss: 1.0938\n",
            "Batch 100 | Loss: 1.1122\n",
            "Batch 110 | Loss: 0.9731\n",
            "Batch 120 | Loss: 0.9248\n",
            "Batch 130 | Loss: 1.0309\n",
            "Batch 140 | Loss: 1.1232\n",
            "Batch 150 | Loss: 0.9526\n",
            "Batch 160 | Loss: 0.9560\n",
            "Batch 170 | Loss: 1.2525\n",
            "Batch 180 | Loss: 1.1117\n",
            "Batch 190 | Loss: 0.8556\n",
            "Batch 200 | Loss: 0.9990\n",
            "Batch 210 | Loss: 1.0807\n",
            "Batch 220 | Loss: 1.2118\n",
            "Batch 230 | Loss: 1.2199\n",
            "Batch 240 | Loss: 1.1044\n",
            "Batch 250 | Loss: 0.8083\n",
            "Batch 260 | Loss: 1.0113\n",
            "Batch 270 | Loss: 1.1975\n",
            "Batch 280 | Loss: 1.0046\n",
            "Batch 290 | Loss: 0.9963\n",
            "Batch 300 | Loss: 0.8397\n",
            "Batch 310 | Loss: 1.0526\n",
            "Batch 320 | Loss: 0.8921\n",
            "Batch 330 | Loss: 1.2298\n",
            "Batch 340 | Loss: 0.9361\n",
            "Batch 350 | Loss: 0.8416\n",
            "Batch 360 | Loss: 0.9781\n",
            "Batch 370 | Loss: 0.9734\n",
            "Batch 380 | Loss: 0.9121\n",
            "Batch 390 | Loss: 1.0385\n",
            "Batch 400 | Loss: 0.8594\n",
            "‚úÖ Epoch 12 | Avg Loss: 1.0298\n",
            "Batch 0 | Loss: 0.8999\n",
            "Batch 10 | Loss: 0.9647\n",
            "Batch 20 | Loss: 0.9236\n",
            "Batch 30 | Loss: 1.1052\n",
            "Batch 40 | Loss: 0.8440\n",
            "Batch 50 | Loss: 0.8856\n",
            "Batch 60 | Loss: 0.8458\n",
            "Batch 70 | Loss: 1.2219\n",
            "Batch 80 | Loss: 1.2117\n",
            "Batch 90 | Loss: 0.9968\n",
            "Batch 100 | Loss: 1.2640\n",
            "Batch 110 | Loss: 1.0023\n",
            "Batch 120 | Loss: 1.2395\n",
            "Batch 130 | Loss: 1.0507\n",
            "Batch 140 | Loss: 1.0323\n",
            "Batch 150 | Loss: 1.0137\n",
            "Batch 160 | Loss: 0.9060\n",
            "Batch 170 | Loss: 0.8247\n",
            "Batch 180 | Loss: 1.1111\n",
            "Batch 190 | Loss: 1.0261\n",
            "Batch 200 | Loss: 1.1392\n",
            "Batch 210 | Loss: 1.2098\n",
            "Batch 220 | Loss: 0.9955\n",
            "Batch 230 | Loss: 0.8674\n",
            "Batch 240 | Loss: 0.8447\n",
            "Batch 250 | Loss: 1.1604\n",
            "Batch 260 | Loss: 1.0401\n",
            "Batch 270 | Loss: 0.7891\n",
            "Batch 280 | Loss: 1.3444\n",
            "Batch 290 | Loss: 1.0015\n",
            "Batch 300 | Loss: 1.0838\n",
            "Batch 310 | Loss: 0.9184\n",
            "Batch 320 | Loss: 0.7685\n",
            "Batch 330 | Loss: 0.9116\n",
            "Batch 340 | Loss: 0.8756\n",
            "Batch 350 | Loss: 1.1162\n",
            "Batch 360 | Loss: 0.9818\n",
            "Batch 370 | Loss: 1.1151\n",
            "Batch 380 | Loss: 0.9886\n",
            "Batch 390 | Loss: 0.9134\n",
            "Batch 400 | Loss: 1.2080\n",
            "‚úÖ Epoch 13 | Avg Loss: 1.0076\n",
            "Batch 0 | Loss: 0.7470\n",
            "Batch 10 | Loss: 1.1793\n",
            "Batch 20 | Loss: 0.8688\n",
            "Batch 30 | Loss: 0.8775\n",
            "Batch 40 | Loss: 1.0525\n",
            "Batch 50 | Loss: 0.8968\n",
            "Batch 60 | Loss: 1.0389\n",
            "Batch 70 | Loss: 1.0439\n",
            "Batch 80 | Loss: 0.8648\n",
            "Batch 90 | Loss: 1.0577\n",
            "Batch 100 | Loss: 0.9068\n",
            "Batch 110 | Loss: 1.1417\n",
            "Batch 120 | Loss: 1.0132\n",
            "Batch 130 | Loss: 1.1224\n",
            "Batch 140 | Loss: 1.0484\n",
            "Batch 150 | Loss: 1.1127\n",
            "Batch 160 | Loss: 1.0294\n",
            "Batch 170 | Loss: 0.8830\n",
            "Batch 180 | Loss: 0.9143\n",
            "Batch 190 | Loss: 0.9790\n",
            "Batch 200 | Loss: 1.1720\n",
            "Batch 210 | Loss: 1.3530\n",
            "Batch 220 | Loss: 0.9765\n",
            "Batch 230 | Loss: 1.1799\n",
            "Batch 240 | Loss: 0.8519\n",
            "Batch 250 | Loss: 0.8423\n",
            "Batch 260 | Loss: 0.9183\n",
            "Batch 270 | Loss: 0.9549\n",
            "Batch 280 | Loss: 0.8560\n",
            "Batch 290 | Loss: 1.0577\n",
            "Batch 300 | Loss: 0.9209\n",
            "Batch 310 | Loss: 0.9586\n",
            "Batch 320 | Loss: 0.8685\n",
            "Batch 330 | Loss: 0.7630\n",
            "Batch 340 | Loss: 1.0145\n",
            "Batch 350 | Loss: 0.7142\n",
            "Batch 360 | Loss: 1.2027\n",
            "Batch 370 | Loss: 1.0311\n",
            "Batch 380 | Loss: 0.7843\n",
            "Batch 390 | Loss: 1.1546\n",
            "Batch 400 | Loss: 1.1952\n",
            "‚úÖ Epoch 14 | Avg Loss: 0.9725\n",
            "Batch 0 | Loss: 0.9911\n",
            "Batch 10 | Loss: 1.2039\n",
            "Batch 20 | Loss: 1.0576\n",
            "Batch 30 | Loss: 0.8630\n",
            "Batch 40 | Loss: 0.9851\n",
            "Batch 50 | Loss: 0.9892\n",
            "Batch 60 | Loss: 0.7525\n",
            "Batch 70 | Loss: 1.0460\n",
            "Batch 80 | Loss: 0.8212\n",
            "Batch 90 | Loss: 0.8930\n",
            "Batch 100 | Loss: 0.9051\n",
            "Batch 110 | Loss: 0.9696\n",
            "Batch 120 | Loss: 0.7466\n",
            "Batch 130 | Loss: 1.0530\n",
            "Batch 140 | Loss: 0.9894\n",
            "Batch 150 | Loss: 1.1459\n",
            "Batch 160 | Loss: 0.9618\n",
            "Batch 170 | Loss: 1.3338\n",
            "Batch 180 | Loss: 0.9398\n",
            "Batch 190 | Loss: 0.8374\n",
            "Batch 200 | Loss: 0.6879\n",
            "Batch 210 | Loss: 1.1571\n",
            "Batch 220 | Loss: 0.8265\n",
            "Batch 230 | Loss: 0.7349\n",
            "Batch 240 | Loss: 0.9387\n",
            "Batch 250 | Loss: 0.8633\n",
            "Batch 260 | Loss: 0.7873\n",
            "Batch 270 | Loss: 0.7232\n",
            "Batch 280 | Loss: 0.8499\n",
            "Batch 290 | Loss: 0.8066\n",
            "Batch 300 | Loss: 0.9879\n",
            "Batch 310 | Loss: 0.8267\n",
            "Batch 320 | Loss: 1.2625\n",
            "Batch 330 | Loss: 1.1312\n",
            "Batch 340 | Loss: 1.1328\n",
            "Batch 350 | Loss: 0.9814\n",
            "Batch 360 | Loss: 0.7502\n",
            "Batch 370 | Loss: 1.1185\n",
            "Batch 380 | Loss: 1.0947\n",
            "Batch 390 | Loss: 1.1119\n",
            "Batch 400 | Loss: 0.9258\n",
            "‚úÖ Epoch 15 | Avg Loss: 0.9623\n",
            "Batch 0 | Loss: 0.9707\n",
            "Batch 10 | Loss: 1.0611\n",
            "Batch 20 | Loss: 0.8452\n",
            "Batch 30 | Loss: 0.7573\n",
            "Batch 40 | Loss: 0.7824\n",
            "Batch 50 | Loss: 0.8107\n",
            "Batch 60 | Loss: 0.9042\n",
            "Batch 70 | Loss: 0.9993\n",
            "Batch 80 | Loss: 1.0134\n",
            "Batch 90 | Loss: 0.7610\n",
            "Batch 100 | Loss: 1.0637\n",
            "Batch 110 | Loss: 0.7710\n",
            "Batch 120 | Loss: 0.9529\n",
            "Batch 130 | Loss: 1.0180\n",
            "Batch 140 | Loss: 0.9974\n",
            "Batch 150 | Loss: 1.0432\n",
            "Batch 160 | Loss: 0.9732\n",
            "Batch 170 | Loss: 1.0428\n",
            "Batch 180 | Loss: 1.2322\n",
            "Batch 190 | Loss: 0.8705\n",
            "Batch 200 | Loss: 1.1801\n",
            "Batch 210 | Loss: 0.8348\n",
            "Batch 220 | Loss: 0.9152\n",
            "Batch 230 | Loss: 0.9342\n",
            "Batch 240 | Loss: 0.8142\n",
            "Batch 250 | Loss: 0.7472\n",
            "Batch 260 | Loss: 0.9533\n",
            "Batch 270 | Loss: 1.0858\n",
            "Batch 280 | Loss: 0.8527\n",
            "Batch 290 | Loss: 0.8823\n",
            "Batch 300 | Loss: 0.7349\n",
            "Batch 310 | Loss: 0.8785\n",
            "Batch 320 | Loss: 0.8874\n",
            "Batch 330 | Loss: 0.8413\n",
            "Batch 340 | Loss: 0.7036\n",
            "Batch 350 | Loss: 0.8908\n",
            "Batch 360 | Loss: 0.7579\n",
            "Batch 370 | Loss: 0.7884\n",
            "Batch 380 | Loss: 1.0449\n",
            "Batch 390 | Loss: 0.7850\n",
            "Batch 400 | Loss: 0.8848\n",
            "‚úÖ Epoch 16 | Avg Loss: 0.9060\n",
            "Batch 0 | Loss: 0.8576\n",
            "Batch 10 | Loss: 0.9189\n",
            "Batch 20 | Loss: 0.7383\n",
            "Batch 30 | Loss: 0.8781\n",
            "Batch 40 | Loss: 0.8580\n",
            "Batch 50 | Loss: 0.9673\n",
            "Batch 60 | Loss: 0.7777\n",
            "Batch 70 | Loss: 0.7576\n",
            "Batch 80 | Loss: 1.3201\n",
            "Batch 90 | Loss: 0.9352\n",
            "Batch 100 | Loss: 1.0431\n",
            "Batch 110 | Loss: 0.9621\n",
            "Batch 120 | Loss: 1.4745\n",
            "Batch 130 | Loss: 0.8107\n",
            "Batch 140 | Loss: 1.0446\n",
            "Batch 150 | Loss: 0.8326\n",
            "Batch 160 | Loss: 0.5582\n",
            "Batch 170 | Loss: 0.9701\n",
            "Batch 180 | Loss: 0.9058\n",
            "Batch 190 | Loss: 0.9914\n",
            "Batch 200 | Loss: 0.6936\n",
            "Batch 210 | Loss: 0.8937\n",
            "Batch 220 | Loss: 0.7489\n",
            "Batch 230 | Loss: 0.7822\n",
            "Batch 240 | Loss: 1.0625\n",
            "Batch 250 | Loss: 0.8808\n",
            "Batch 260 | Loss: 0.7454\n",
            "Batch 270 | Loss: 0.8457\n",
            "Batch 280 | Loss: 0.8410\n",
            "Batch 290 | Loss: 0.7688\n",
            "Batch 300 | Loss: 0.7624\n",
            "Batch 310 | Loss: 0.8234\n",
            "Batch 320 | Loss: 0.7509\n",
            "Batch 330 | Loss: 0.7564\n",
            "Batch 340 | Loss: 0.7630\n",
            "Batch 350 | Loss: 0.6484\n",
            "Batch 360 | Loss: 1.2135\n",
            "Batch 370 | Loss: 0.9070\n",
            "Batch 380 | Loss: 0.8260\n",
            "Batch 390 | Loss: 0.9423\n",
            "Batch 400 | Loss: 0.8115\n",
            "‚úÖ Epoch 17 | Avg Loss: 0.8874\n",
            "Batch 0 | Loss: 1.0258\n",
            "Batch 10 | Loss: 0.7828\n",
            "Batch 20 | Loss: 0.8237\n",
            "Batch 30 | Loss: 0.8213\n",
            "Batch 40 | Loss: 0.8223\n",
            "Batch 50 | Loss: 0.9103\n",
            "Batch 60 | Loss: 1.0544\n",
            "Batch 70 | Loss: 0.7302\n",
            "Batch 80 | Loss: 0.8273\n",
            "Batch 90 | Loss: 0.6653\n",
            "Batch 100 | Loss: 0.7541\n",
            "Batch 110 | Loss: 0.9620\n",
            "Batch 120 | Loss: 0.8531\n",
            "Batch 130 | Loss: 0.8177\n",
            "Batch 140 | Loss: 0.7402\n",
            "Batch 150 | Loss: 0.9251\n",
            "Batch 160 | Loss: 0.7677\n",
            "Batch 170 | Loss: 0.8630\n",
            "Batch 180 | Loss: 0.6934\n",
            "Batch 190 | Loss: 0.8924\n",
            "Batch 200 | Loss: 0.9536\n",
            "Batch 210 | Loss: 0.7358\n",
            "Batch 220 | Loss: 0.9314\n",
            "Batch 230 | Loss: 0.7825\n",
            "Batch 240 | Loss: 0.7589\n",
            "Batch 250 | Loss: 0.6955\n",
            "Batch 260 | Loss: 0.8121\n",
            "Batch 270 | Loss: 0.6446\n",
            "Batch 280 | Loss: 0.9121\n",
            "Batch 290 | Loss: 0.9164\n",
            "Batch 300 | Loss: 0.5258\n",
            "Batch 310 | Loss: 0.6210\n",
            "Batch 320 | Loss: 0.7120\n",
            "Batch 330 | Loss: 0.8647\n",
            "Batch 340 | Loss: 0.6133\n",
            "Batch 350 | Loss: 0.7605\n",
            "Batch 360 | Loss: 0.8287\n",
            "Batch 370 | Loss: 0.8527\n",
            "Batch 380 | Loss: 0.7470\n",
            "Batch 390 | Loss: 1.1173\n",
            "Batch 400 | Loss: 0.7143\n",
            "‚úÖ Epoch 18 | Avg Loss: 0.8443\n",
            "Batch 0 | Loss: 0.8426\n",
            "Batch 10 | Loss: 0.9255\n",
            "Batch 20 | Loss: 0.7647\n",
            "Batch 30 | Loss: 0.7596\n",
            "Batch 40 | Loss: 0.7317\n",
            "Batch 50 | Loss: 0.6636\n",
            "Batch 60 | Loss: 0.8253\n",
            "Batch 70 | Loss: 0.7549\n",
            "Batch 80 | Loss: 0.5877\n",
            "Batch 90 | Loss: 1.0418\n",
            "Batch 100 | Loss: 1.0766\n",
            "Batch 110 | Loss: 0.7045\n",
            "Batch 120 | Loss: 0.7805\n",
            "Batch 130 | Loss: 0.7795\n",
            "Batch 140 | Loss: 0.8173\n",
            "Batch 150 | Loss: 0.8881\n",
            "Batch 160 | Loss: 0.5619\n",
            "Batch 170 | Loss: 0.6727\n",
            "Batch 180 | Loss: 0.8094\n",
            "Batch 190 | Loss: 1.1219\n",
            "Batch 200 | Loss: 0.9592\n",
            "Batch 210 | Loss: 0.8438\n",
            "Batch 220 | Loss: 0.8421\n",
            "Batch 230 | Loss: 1.2774\n",
            "Batch 240 | Loss: 0.8666\n",
            "Batch 250 | Loss: 0.9022\n",
            "Batch 260 | Loss: 0.9441\n",
            "Batch 270 | Loss: 0.8871\n",
            "Batch 280 | Loss: 0.7335\n",
            "Batch 290 | Loss: 0.5863\n",
            "Batch 300 | Loss: 0.8221\n",
            "Batch 310 | Loss: 0.7542\n",
            "Batch 320 | Loss: 0.8893\n",
            "Batch 330 | Loss: 0.9732\n",
            "Batch 340 | Loss: 0.9682\n",
            "Batch 350 | Loss: 0.7493\n",
            "Batch 360 | Loss: 0.9409\n",
            "Batch 370 | Loss: 0.9556\n",
            "Batch 380 | Loss: 0.7668\n",
            "Batch 390 | Loss: 0.8232\n",
            "Batch 400 | Loss: 0.6894\n",
            "‚úÖ Epoch 19 | Avg Loss: 0.8137\n",
            "Batch 0 | Loss: 0.7716\n",
            "Batch 10 | Loss: 0.6745\n",
            "Batch 20 | Loss: 0.6067\n",
            "Batch 30 | Loss: 0.6485\n",
            "Batch 40 | Loss: 0.6613\n",
            "Batch 50 | Loss: 0.8661\n",
            "Batch 60 | Loss: 1.1127\n",
            "Batch 70 | Loss: 0.7254\n",
            "Batch 80 | Loss: 0.9730\n",
            "Batch 90 | Loss: 0.5775\n",
            "Batch 100 | Loss: 0.9191\n",
            "Batch 110 | Loss: 0.6269\n",
            "Batch 120 | Loss: 1.1547\n",
            "Batch 130 | Loss: 0.7821\n",
            "Batch 140 | Loss: 0.6258\n",
            "Batch 150 | Loss: 0.9501\n",
            "Batch 160 | Loss: 1.0080\n",
            "Batch 170 | Loss: 0.8345\n",
            "Batch 180 | Loss: 0.9089\n",
            "Batch 190 | Loss: 1.0205\n",
            "Batch 200 | Loss: 0.6485\n",
            "Batch 210 | Loss: 0.6244\n",
            "Batch 220 | Loss: 0.9147\n",
            "Batch 230 | Loss: 1.0300\n",
            "Batch 240 | Loss: 0.7504\n",
            "Batch 250 | Loss: 0.7770\n",
            "Batch 260 | Loss: 0.8000\n",
            "Batch 270 | Loss: 0.8331\n",
            "Batch 280 | Loss: 0.6459\n",
            "Batch 290 | Loss: 0.8694\n",
            "Batch 300 | Loss: 0.7222\n",
            "Batch 310 | Loss: 0.7663\n",
            "Batch 320 | Loss: 0.5831\n",
            "Batch 330 | Loss: 0.8513\n",
            "Batch 340 | Loss: 0.8781\n",
            "Batch 350 | Loss: 0.8283\n",
            "Batch 360 | Loss: 0.9663\n",
            "Batch 370 | Loss: 0.6699\n",
            "Batch 380 | Loss: 0.6142\n",
            "Batch 390 | Loss: 0.7433\n",
            "Batch 400 | Loss: 0.6059\n",
            "‚úÖ Epoch 20 | Avg Loss: 0.8015\n",
            "Batch 0 | Loss: 0.8212\n",
            "Batch 10 | Loss: 0.6451\n",
            "Batch 20 | Loss: 0.8717\n",
            "Batch 30 | Loss: 0.6421\n",
            "Batch 40 | Loss: 1.3974\n",
            "Batch 50 | Loss: 0.7379\n",
            "Batch 60 | Loss: 0.4598\n",
            "Batch 70 | Loss: 0.9476\n",
            "Batch 80 | Loss: 1.0926\n",
            "Batch 90 | Loss: 0.6968\n",
            "Batch 100 | Loss: 0.9208\n",
            "Batch 110 | Loss: 0.6598\n",
            "Batch 120 | Loss: 0.6952\n",
            "Batch 130 | Loss: 0.7878\n",
            "Batch 140 | Loss: 0.9033\n",
            "Batch 150 | Loss: 0.6363\n",
            "Batch 160 | Loss: 0.7684\n",
            "Batch 170 | Loss: 0.7341\n",
            "Batch 180 | Loss: 0.7947\n",
            "Batch 190 | Loss: 0.5703\n",
            "Batch 200 | Loss: 0.7086\n",
            "Batch 210 | Loss: 0.5793\n",
            "Batch 220 | Loss: 0.5411\n",
            "Batch 230 | Loss: 0.5206\n",
            "Batch 240 | Loss: 0.7920\n",
            "Batch 250 | Loss: 0.7952\n",
            "Batch 260 | Loss: 0.7354\n",
            "Batch 270 | Loss: 0.4895\n",
            "Batch 280 | Loss: 0.6825\n",
            "Batch 290 | Loss: 0.6053\n",
            "Batch 300 | Loss: 0.6777\n",
            "Batch 310 | Loss: 0.8381\n",
            "Batch 320 | Loss: 0.4546\n",
            "Batch 330 | Loss: 0.4778\n",
            "Batch 340 | Loss: 0.6062\n",
            "Batch 350 | Loss: 0.6848\n",
            "Batch 360 | Loss: 0.7730\n",
            "Batch 370 | Loss: 0.9201\n",
            "Batch 380 | Loss: 0.5702\n",
            "Batch 390 | Loss: 1.1002\n",
            "Batch 400 | Loss: 0.5777\n",
            "‚úÖ Epoch 21 | Avg Loss: 0.7632\n",
            "Batch 0 | Loss: 0.5915\n",
            "Batch 10 | Loss: 0.6247\n",
            "Batch 20 | Loss: 0.9144\n",
            "Batch 30 | Loss: 0.6261\n",
            "Batch 40 | Loss: 1.0678\n",
            "Batch 50 | Loss: 0.5712\n",
            "Batch 60 | Loss: 0.5906\n",
            "Batch 70 | Loss: 0.6480\n",
            "Batch 80 | Loss: 0.6748\n",
            "Batch 90 | Loss: 1.1607\n",
            "Batch 100 | Loss: 0.9001\n",
            "Batch 110 | Loss: 0.4519\n",
            "Batch 120 | Loss: 0.6899\n",
            "Batch 130 | Loss: 0.8454\n",
            "Batch 140 | Loss: 0.8102\n",
            "Batch 150 | Loss: 0.8833\n",
            "Batch 160 | Loss: 0.5696\n",
            "Batch 170 | Loss: 0.8578\n",
            "Batch 180 | Loss: 0.6519\n",
            "Batch 190 | Loss: 0.6583\n",
            "Batch 200 | Loss: 0.6526\n",
            "Batch 210 | Loss: 0.7686\n",
            "Batch 220 | Loss: 0.4188\n",
            "Batch 230 | Loss: 0.7103\n",
            "Batch 240 | Loss: 0.6635\n",
            "Batch 250 | Loss: 0.7016\n",
            "Batch 260 | Loss: 0.7301\n",
            "Batch 270 | Loss: 0.7543\n",
            "Batch 280 | Loss: 0.7125\n",
            "Batch 290 | Loss: 0.6130\n",
            "Batch 300 | Loss: 0.5493\n",
            "Batch 310 | Loss: 0.3855\n",
            "Batch 320 | Loss: 0.7468\n",
            "Batch 330 | Loss: 0.9537\n",
            "Batch 340 | Loss: 0.7250\n",
            "Batch 350 | Loss: 0.6733\n",
            "Batch 360 | Loss: 0.6829\n",
            "Batch 370 | Loss: 0.7124\n",
            "Batch 380 | Loss: 0.6889\n",
            "Batch 390 | Loss: 0.7492\n",
            "Batch 400 | Loss: 0.8252\n",
            "‚úÖ Epoch 22 | Avg Loss: 0.7346\n",
            "Batch 0 | Loss: 0.8703\n",
            "Batch 10 | Loss: 0.6683\n",
            "Batch 20 | Loss: 0.4703\n",
            "Batch 30 | Loss: 0.7603\n",
            "Batch 40 | Loss: 0.7073\n",
            "Batch 50 | Loss: 0.8675\n",
            "Batch 60 | Loss: 0.5828\n",
            "Batch 70 | Loss: 0.6093\n",
            "Batch 80 | Loss: 0.5919\n",
            "Batch 90 | Loss: 0.7744\n",
            "Batch 100 | Loss: 0.7126\n",
            "Batch 110 | Loss: 0.7306\n",
            "Batch 120 | Loss: 0.6892\n",
            "Batch 130 | Loss: 0.7776\n",
            "Batch 140 | Loss: 1.1539\n",
            "Batch 150 | Loss: 0.5920\n",
            "Batch 160 | Loss: 0.8107\n",
            "Batch 170 | Loss: 0.6868\n",
            "Batch 180 | Loss: 0.6178\n",
            "Batch 190 | Loss: 0.7633\n",
            "Batch 200 | Loss: 0.8052\n",
            "Batch 210 | Loss: 0.4583\n",
            "Batch 220 | Loss: 0.5208\n",
            "Batch 230 | Loss: 0.7130\n",
            "Batch 240 | Loss: 0.7285\n",
            "Batch 250 | Loss: 0.6947\n",
            "Batch 260 | Loss: 0.6299\n",
            "Batch 270 | Loss: 0.9734\n",
            "Batch 280 | Loss: 0.6096\n",
            "Batch 290 | Loss: 0.7044\n",
            "Batch 300 | Loss: 0.5974\n",
            "Batch 310 | Loss: 0.6311\n",
            "Batch 320 | Loss: 0.4559\n",
            "Batch 330 | Loss: 0.4548\n",
            "Batch 340 | Loss: 0.8318\n",
            "Batch 350 | Loss: 0.6501\n",
            "Batch 360 | Loss: 0.8720\n",
            "Batch 370 | Loss: 0.4677\n",
            "Batch 380 | Loss: 0.5793\n",
            "Batch 390 | Loss: 0.7380\n",
            "Batch 400 | Loss: 0.5372\n",
            "‚úÖ Epoch 23 | Avg Loss: 0.7108\n",
            "Batch 0 | Loss: 0.6695\n",
            "Batch 10 | Loss: 0.6178\n",
            "Batch 20 | Loss: 0.7528\n",
            "Batch 30 | Loss: 0.9443\n",
            "Batch 40 | Loss: 0.7554\n",
            "Batch 50 | Loss: 0.6041\n",
            "Batch 60 | Loss: 0.8250\n",
            "Batch 70 | Loss: 0.7251\n",
            "Batch 80 | Loss: 0.6730\n",
            "Batch 90 | Loss: 0.3916\n",
            "Batch 100 | Loss: 0.5730\n",
            "Batch 110 | Loss: 0.4713\n",
            "Batch 120 | Loss: 0.4914\n",
            "Batch 130 | Loss: 0.6429\n",
            "Batch 140 | Loss: 0.4430\n",
            "Batch 150 | Loss: 0.5550\n",
            "Batch 160 | Loss: 0.6796\n",
            "Batch 170 | Loss: 0.5824\n",
            "Batch 180 | Loss: 0.4944\n",
            "Batch 190 | Loss: 0.8759\n",
            "Batch 200 | Loss: 0.8891\n",
            "Batch 210 | Loss: 0.7771\n",
            "Batch 220 | Loss: 0.6216\n",
            "Batch 230 | Loss: 0.6579\n",
            "Batch 240 | Loss: 0.3619\n",
            "Batch 250 | Loss: 0.7015\n",
            "Batch 260 | Loss: 0.8951\n",
            "Batch 270 | Loss: 0.7872\n",
            "Batch 280 | Loss: 1.4875\n",
            "Batch 290 | Loss: 0.8566\n",
            "Batch 300 | Loss: 0.5125\n",
            "Batch 310 | Loss: 0.4912\n",
            "Batch 320 | Loss: 0.5700\n",
            "Batch 330 | Loss: 0.8151\n",
            "Batch 340 | Loss: 0.8686\n",
            "Batch 350 | Loss: 0.2624\n",
            "Batch 360 | Loss: 0.5316\n",
            "Batch 370 | Loss: 0.5962\n",
            "Batch 380 | Loss: 0.7011\n",
            "Batch 390 | Loss: 0.5545\n",
            "Batch 400 | Loss: 0.6963\n",
            "‚úÖ Epoch 24 | Avg Loss: 0.6837\n",
            "Batch 0 | Loss: 0.6674\n",
            "Batch 10 | Loss: 1.0277\n",
            "Batch 20 | Loss: 0.5597\n",
            "Batch 30 | Loss: 0.5379\n",
            "Batch 40 | Loss: 0.5570\n",
            "Batch 50 | Loss: 0.6638\n",
            "Batch 60 | Loss: 0.4685\n",
            "Batch 70 | Loss: 0.5920\n",
            "Batch 80 | Loss: 0.7425\n",
            "Batch 90 | Loss: 0.6628\n",
            "Batch 100 | Loss: 0.4274\n",
            "Batch 110 | Loss: 0.5904\n",
            "Batch 120 | Loss: 0.5993\n",
            "Batch 130 | Loss: 1.1609\n",
            "Batch 140 | Loss: 0.8024\n",
            "Batch 150 | Loss: 0.5629\n",
            "Batch 160 | Loss: 0.6949\n",
            "Batch 170 | Loss: 0.7882\n",
            "Batch 180 | Loss: 0.8900\n",
            "Batch 190 | Loss: 0.4087\n",
            "Batch 200 | Loss: 0.4923\n",
            "Batch 210 | Loss: 0.5063\n",
            "Batch 220 | Loss: 0.5454\n",
            "Batch 230 | Loss: 0.5548\n",
            "Batch 240 | Loss: 0.6120\n",
            "Batch 250 | Loss: 0.3664\n",
            "Batch 260 | Loss: 0.6524\n",
            "Batch 270 | Loss: 0.4728\n",
            "Batch 280 | Loss: 0.5145\n",
            "Batch 290 | Loss: 0.8204\n",
            "Batch 300 | Loss: 0.5908\n",
            "Batch 310 | Loss: 0.5538\n",
            "Batch 320 | Loss: 0.4147\n",
            "Batch 330 | Loss: 0.5840\n",
            "Batch 340 | Loss: 0.4088\n",
            "Batch 350 | Loss: 0.4782\n",
            "Batch 360 | Loss: 0.6017\n",
            "Batch 370 | Loss: 0.5270\n",
            "Batch 380 | Loss: 0.5319\n",
            "Batch 390 | Loss: 0.4161\n",
            "Batch 400 | Loss: 0.8968\n",
            "‚úÖ Epoch 25 | Avg Loss: 0.6605\n",
            "Batch 0 | Loss: 0.7282\n",
            "Batch 10 | Loss: 0.6501\n",
            "Batch 20 | Loss: 0.5667\n",
            "Batch 30 | Loss: 0.5469\n",
            "Batch 40 | Loss: 0.5721\n",
            "Batch 50 | Loss: 0.7966\n",
            "Batch 60 | Loss: 0.6677\n",
            "Batch 70 | Loss: 1.1201\n",
            "Batch 80 | Loss: 0.5166\n",
            "Batch 90 | Loss: 0.6674\n",
            "Batch 100 | Loss: 0.4483\n",
            "Batch 110 | Loss: 0.6149\n",
            "Batch 120 | Loss: 0.6009\n",
            "Batch 130 | Loss: 0.5227\n",
            "Batch 140 | Loss: 1.2846\n",
            "Batch 150 | Loss: 0.4313\n",
            "Batch 160 | Loss: 0.4274\n",
            "Batch 170 | Loss: 0.4733\n",
            "Batch 180 | Loss: 0.6661\n",
            "Batch 190 | Loss: 0.4670\n",
            "Batch 200 | Loss: 0.4587\n",
            "Batch 210 | Loss: 0.5251\n",
            "Batch 220 | Loss: 0.7530\n",
            "Batch 230 | Loss: 0.7409\n",
            "Batch 240 | Loss: 0.6599\n",
            "Batch 250 | Loss: 0.8008\n",
            "Batch 260 | Loss: 0.6174\n",
            "Batch 270 | Loss: 0.7130\n",
            "Batch 280 | Loss: 0.6406\n",
            "Batch 290 | Loss: 0.2595\n",
            "Batch 300 | Loss: 0.5063\n",
            "Batch 310 | Loss: 0.3701\n",
            "Batch 320 | Loss: 0.4915\n",
            "Batch 330 | Loss: 0.5780\n",
            "Batch 340 | Loss: 0.8241\n",
            "Batch 350 | Loss: 0.4927\n",
            "Batch 360 | Loss: 0.4993\n",
            "Batch 370 | Loss: 0.8625\n",
            "Batch 380 | Loss: 0.5809\n",
            "Batch 390 | Loss: 0.6142\n",
            "Batch 400 | Loss: 0.6371\n",
            "‚úÖ Epoch 26 | Avg Loss: 0.6303\n",
            "Batch 0 | Loss: 0.7133\n",
            "Batch 10 | Loss: 0.7704\n",
            "Batch 20 | Loss: 0.5579\n",
            "Batch 30 | Loss: 0.7072\n",
            "Batch 40 | Loss: 0.5992\n",
            "Batch 50 | Loss: 0.7595\n",
            "Batch 60 | Loss: 0.3896\n",
            "Batch 70 | Loss: 0.5874\n",
            "Batch 80 | Loss: 0.6564\n",
            "Batch 90 | Loss: 0.4521\n",
            "Batch 100 | Loss: 0.4375\n",
            "Batch 110 | Loss: 0.6082\n",
            "Batch 120 | Loss: 0.7082\n",
            "Batch 130 | Loss: 0.8389\n",
            "Batch 140 | Loss: 0.8027\n",
            "Batch 150 | Loss: 0.4400\n",
            "Batch 160 | Loss: 0.3667\n",
            "Batch 170 | Loss: 0.6369\n",
            "Batch 180 | Loss: 0.4982\n",
            "Batch 190 | Loss: 1.2637\n",
            "Batch 200 | Loss: 0.3863\n",
            "Batch 210 | Loss: 0.3829\n",
            "Batch 220 | Loss: 0.6923\n",
            "Batch 230 | Loss: 0.6954\n",
            "Batch 240 | Loss: 0.4073\n",
            "Batch 250 | Loss: 0.6044\n",
            "Batch 260 | Loss: 0.4196\n",
            "Batch 270 | Loss: 0.3591\n",
            "Batch 280 | Loss: 0.5131\n",
            "Batch 290 | Loss: 1.0631\n",
            "Batch 300 | Loss: 0.7675\n",
            "Batch 310 | Loss: 0.5522\n",
            "Batch 320 | Loss: 0.5425\n",
            "Batch 330 | Loss: 0.4588\n",
            "Batch 340 | Loss: 0.8080\n",
            "Batch 350 | Loss: 0.4446\n",
            "Batch 360 | Loss: 0.6893\n",
            "Batch 370 | Loss: 0.4973\n",
            "Batch 380 | Loss: 0.9186\n",
            "Batch 390 | Loss: 0.6312\n",
            "Batch 400 | Loss: 0.7632\n",
            "‚úÖ Epoch 27 | Avg Loss: 0.6039\n",
            "Batch 0 | Loss: 0.6129\n",
            "Batch 10 | Loss: 0.4003\n",
            "Batch 20 | Loss: 0.7100\n",
            "Batch 30 | Loss: 0.2728\n",
            "Batch 40 | Loss: 0.6477\n",
            "Batch 50 | Loss: 0.5659\n",
            "Batch 60 | Loss: 0.5763\n",
            "Batch 70 | Loss: 0.8523\n",
            "Batch 80 | Loss: 0.6065\n",
            "Batch 90 | Loss: 0.5246\n",
            "Batch 100 | Loss: 0.4807\n",
            "Batch 110 | Loss: 0.8509\n",
            "Batch 120 | Loss: 0.5775\n",
            "Batch 130 | Loss: 0.6636\n",
            "Batch 140 | Loss: 0.4514\n",
            "Batch 150 | Loss: 0.6768\n",
            "Batch 160 | Loss: 0.7602\n",
            "Batch 170 | Loss: 0.9456\n",
            "Batch 180 | Loss: 0.7271\n",
            "Batch 190 | Loss: 0.5462\n",
            "Batch 200 | Loss: 0.4651\n",
            "Batch 210 | Loss: 0.5522\n",
            "Batch 220 | Loss: 0.4690\n",
            "Batch 230 | Loss: 0.4974\n",
            "Batch 240 | Loss: 0.5848\n",
            "Batch 250 | Loss: 0.4501\n",
            "Batch 260 | Loss: 0.5981\n",
            "Batch 270 | Loss: 0.6786\n",
            "Batch 280 | Loss: 0.6997\n",
            "Batch 290 | Loss: 0.5357\n",
            "Batch 300 | Loss: 0.6559\n",
            "Batch 310 | Loss: 0.3456\n",
            "Batch 320 | Loss: 0.2640\n",
            "Batch 330 | Loss: 0.7782\n",
            "Batch 340 | Loss: 0.2480\n",
            "Batch 350 | Loss: 0.4367\n",
            "Batch 360 | Loss: 0.4428\n",
            "Batch 370 | Loss: 0.5694\n",
            "Batch 380 | Loss: 0.3997\n",
            "Batch 390 | Loss: 0.3976\n",
            "Batch 400 | Loss: 0.6498\n",
            "‚úÖ Epoch 28 | Avg Loss: 0.5983\n",
            "Batch 0 | Loss: 0.6174\n",
            "Batch 10 | Loss: 0.4040\n",
            "Batch 20 | Loss: 0.7666\n",
            "Batch 30 | Loss: 0.7790\n",
            "Batch 40 | Loss: 0.3809\n",
            "Batch 50 | Loss: 0.7296\n",
            "Batch 60 | Loss: 0.7388\n",
            "Batch 70 | Loss: 0.7566\n",
            "Batch 80 | Loss: 0.7646\n",
            "Batch 90 | Loss: 0.4541\n",
            "Batch 100 | Loss: 0.7821\n",
            "Batch 110 | Loss: 0.6084\n",
            "Batch 120 | Loss: 0.4172\n",
            "Batch 130 | Loss: 0.6047\n",
            "Batch 140 | Loss: 0.3789\n",
            "Batch 150 | Loss: 0.7484\n",
            "Batch 160 | Loss: 0.3443\n",
            "Batch 170 | Loss: 0.8328\n",
            "Batch 180 | Loss: 0.1506\n",
            "Batch 190 | Loss: 0.5496\n",
            "Batch 200 | Loss: 0.4084\n",
            "Batch 210 | Loss: 0.4340\n",
            "Batch 220 | Loss: 0.4964\n",
            "Batch 230 | Loss: 0.4682\n",
            "Batch 240 | Loss: 0.7921\n",
            "Batch 250 | Loss: 0.3536\n",
            "Batch 260 | Loss: 0.5518\n",
            "Batch 270 | Loss: 0.4736\n",
            "Batch 280 | Loss: 0.4688\n",
            "Batch 290 | Loss: 0.5340\n",
            "Batch 300 | Loss: 0.5016\n",
            "Batch 310 | Loss: 0.3936\n",
            "Batch 320 | Loss: 0.5603\n",
            "Batch 330 | Loss: 0.7842\n",
            "Batch 340 | Loss: 0.4852\n",
            "Batch 350 | Loss: 0.3380\n",
            "Batch 360 | Loss: 0.2555\n",
            "Batch 370 | Loss: 0.3491\n",
            "Batch 380 | Loss: 0.4612\n",
            "Batch 390 | Loss: 0.3650\n",
            "Batch 400 | Loss: 0.7337\n",
            "‚úÖ Epoch 29 | Avg Loss: 0.5633\n",
            "üíæ Done! Model saved to 'sinhala-pronunciation-model' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scoring engine"
      ],
      "metadata": {
        "id": "xIOoFXqk2RCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio.functional as F\n",
        "\n",
        "def evaluate_pronunciation(wav_path, target_phonemes):\n",
        "    model.eval()\n",
        "\n",
        "    wav, sr = torchaudio.load(wav_path)\n",
        "    if sr != 16000:\n",
        "        wav = torchaudio.functional.resample(wav, sr, 16000)\n",
        "\n",
        "    inputs = processor(\n",
        "        wav.squeeze().numpy(),\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_values.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emissions = model(inputs).logits.log_softmax(-1)\n",
        "\n",
        "    target_ids = torch.tensor(\n",
        "        [training_vocab[p] for p in target_phonemes],\n",
        "        device=device\n",
        "    ).unsqueeze(0)\n",
        "\n",
        "    blank_id = processor.tokenizer.pad_token_id\n",
        "\n",
        "    alignment, scores = F.forced_align(\n",
        "        emissions,\n",
        "        target_ids,\n",
        "        blank=blank_id\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "    for i, p in enumerate(target_phonemes):\n",
        "        raw_gop = scores[0][i].item()\n",
        "        confidence = normalize_gop(raw_gop)\n",
        "\n",
        "        results.append({\n",
        "            \"phoneme\": p,\n",
        "            \"raw_log_prob\": raw_gop,\n",
        "            \"score\": confidence,\n",
        "            \"feedback\": get_sinhala_feedback(confidence)\n",
        "        })\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "KwBK6v8jgAle"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize GOP\n",
        "\n",
        "import math\n",
        "\n",
        "def normalize_gop(log_prob, min_lp=-10.0, max_lp=-6.0):\n",
        "    log_prob = max(min(log_prob, max_lp), min_lp)\n",
        "    return (log_prob - min_lp) / (max_lp - min_lp)\n"
      ],
      "metadata": {
        "id": "2SuJnihw3Z3U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sinhala Feedback"
      ],
      "metadata": {
        "id": "JdF-VC_62YPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sinhala_feedback(score):\n",
        "    if score >= 0.75:\n",
        "        return \"‡∂â‡∂≠‡∑è ‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í! ‡∑Å‡∂∂‡∑ä‡∂Ø‡∂∫ ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í‡∑Ä ‡∂á‡∑Ñ‡∑ô‡∂±‡∑Ä‡∑è. üåü\"\n",
        "    elif score >= 0.55:\n",
        "        return \"‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í. ‡∂≠‡∑Ä ‡∂ß‡∑í‡∂ö‡∂ö‡∑ä ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∑Ä‡∑ô‡∂∏‡∑î. üëç\"\n",
        "    elif score >= 0.35:\n",
        "        return \"‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂∏‡∑î. ‡∂Ø‡∑í‡∑Ä ‡∑É‡∑Ñ ‡∂≠‡∑ú‡∂Ω‡∑ä ‡∂¥‡∑í‡∑Ñ‡∑í‡∂ß‡∑ì‡∂∏ ‡∂∂‡∂Ω‡∂±‡∑ä‡∂±. üëÇ\"\n",
        "    else:\n",
        "        return \"‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í‡∑Ä ‡∂¥‡∑Ä‡∑É‡∂±‡∑ä‡∂±. ‚ùå\"\n"
      ],
      "metadata": {
        "id": "rAz4Tol02am6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "RZ_oDeTQ3c52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = \"/content/drive/MyDrive/user.wav\"\n",
        "test_targets = [\"b\", \"a\", \"l\", \"l\", \"a:\"]\n",
        "\n",
        "results = evaluate_pronunciation(test_file, test_targets)\n",
        "\n",
        "print(f\"--- ‡∂ã‡∂†‡∑ä‡∂†‡∑è‡∂ª‡∂´ ‡∑Ä‡∑è‡∂ª‡∑ä‡∂≠‡∑è‡∑Ä (Pronunciation Report) ---\")\n",
        "for r in results:\n",
        "    print(f\"Phoneme: {r['phoneme']} | Score: {r['score']:.2f}\")\n",
        "    print(f\"Feedback: {r['feedback']}\")\n",
        "    print(r[\"phoneme\"], r[\"raw_log_prob\"])\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJIvdN5x3egI",
        "outputId": "4d4695ca-139b-4de4-fa43-19b743f1e9b3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ‡∂ã‡∂†‡∑ä‡∂†‡∑è‡∂ª‡∂´ ‡∑Ä‡∑è‡∂ª‡∑ä‡∂≠‡∑è‡∑Ä (Pronunciation Report) ---\n",
            "Phoneme: b | Score: 0.77\n",
            "Feedback: ‡∂â‡∂≠‡∑è ‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í! ‡∑Å‡∂∂‡∑ä‡∂Ø‡∂∫ ‡∂¥‡∑ê‡∑Ñ‡∑ê‡∂Ø‡∑í‡∂Ω‡∑í‡∑Ä ‡∂á‡∑Ñ‡∑ô‡∂±‡∑Ä‡∑è. üåü\n",
            "b -6.924605369567871\n",
            "------------------------------\n",
            "Phoneme: a | Score: 0.58\n",
            "Feedback: ‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í. ‡∂≠‡∑Ä ‡∂ß‡∑í‡∂ö‡∂ö‡∑ä ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∑Ä‡∑ô‡∂∏‡∑î. üëç\n",
            "a -7.6969218254089355\n",
            "------------------------------\n",
            "Phoneme: l | Score: 0.52\n",
            "Feedback: ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂∏‡∑î. ‡∂Ø‡∑í‡∑Ä ‡∑É‡∑Ñ ‡∂≠‡∑ú‡∂Ω‡∑ä ‡∂¥‡∑í‡∑Ñ‡∑í‡∂ß‡∑ì‡∂∏ ‡∂∂‡∂Ω‡∂±‡∑ä‡∂±. üëÇ\n",
            "l -7.926098823547363\n",
            "------------------------------\n",
            "Phoneme: l | Score: 0.58\n",
            "Feedback: ‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í. ‡∂≠‡∑Ä ‡∂ß‡∑í‡∂ö‡∂ö‡∑ä ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∑Ä‡∑ô‡∂∏‡∑î. üëç\n",
            "l -7.694340705871582\n",
            "------------------------------\n",
            "Phoneme: a: | Score: 0.66\n",
            "Feedback: ‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í. ‡∂≠‡∑Ä ‡∂ß‡∑í‡∂ö‡∂ö‡∑ä ‡∂¥‡∑î‡∑Ñ‡∑î‡∂´‡∑î ‡∑Ä‡∑ô‡∂∏‡∑î. üëç\n",
            "a: -7.3587751388549805\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2354664699.py:26: UserWarning: torchaudio.functional._alignment.forced_align has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  alignment, scores = F.forced_align(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emzwEyCo3jJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}